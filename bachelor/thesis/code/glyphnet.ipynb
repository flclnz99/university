{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "mT41bZXOK9TO"
   },
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image, ImageDraw, ImageFont, ImageEnhance\n",
    "import urllib.request\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "m8BtjP0yLJba"
   },
   "outputs": [],
   "source": [
    "data = pickle.load(urllib.request.urlopen('https://github.com/endgameinc/homoglyph/blob/master/data/process_spoof.pkl?raw=true'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "cS2g3v6fLMDW"
   },
   "outputs": [],
   "source": [
    "font = '/content/font/Arial.ttf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Ldg2SdevLact"
   },
   "outputs": [],
   "source": [
    "#creating images\n",
    "def create_image(text, path):\n",
    "    image = Image.new('L', (150, 12))\n",
    "    fnt = ImageFont.truetype(font, 10)\n",
    "    d = ImageDraw.Draw(image)\n",
    "    d.text((0, 0), text, font=fnt, fill = (255))\n",
    "    enhancer = ImageEnhance.Contrast(image)\n",
    "    im_output = enhancer.enhance(1.5)\n",
    "    #transposed  = img.transpose(Image.ROTATE_90)\n",
    "    im_output.save(path + text + '.png', 'PNG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "noPwsy1DM3gv"
   },
   "outputs": [],
   "source": [
    "#data division, manipulating real domains (score of 0.0)\n",
    "train = [real[0] for real in data['train'] if real[2] == 0.0]\n",
    "test = [real[0] for real in data['test'] if real[2] == 0.0]\n",
    "valid = [real[0] for real in data['validate'] if real[2] == 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a0DePdPl0LKu",
    "outputId": "c880a91e-6aa1-4a1b-8ea7-2b85b06976d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('PQBOOTX.EXE', 'pqƀoőtẍ.exe', 1.0)\n"
     ]
    }
   ],
   "source": [
    "print(data['train'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "qiA_7mwbM5_1"
   },
   "outputs": [],
   "source": [
    "#eliminating duplicates\n",
    "uniq_train = list(set(train))\n",
    "uniq_test = list(set(test))\n",
    "uniq_valid = list(set(valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Y7w2Erk2M8b_"
   },
   "outputs": [],
   "source": [
    "#saving data in files\n",
    "with open(\"real_train.txt\", \"wb\") as fp:\n",
    "    pickle.dump(uniq_train, fp)\n",
    "\n",
    "with open(\"real_test.txt\", \"wb\") as fp:\n",
    "    pickle.dump(uniq_test, fp)\n",
    "\n",
    "with open(\"real_valid.txt\", \"wb\") as fp:\n",
    "    pickle.dump(uniq_valid, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "JzJTBR6zM-rT"
   },
   "outputs": [],
   "source": [
    "with open(\"real_train.txt\", \"rb\") as fp:\n",
    "    real_train = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "sXX9vZalNAst"
   },
   "outputs": [],
   "source": [
    "with open(\"real_test.txt\", \"rb\") as fp:\n",
    "    real_test = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "Yom-NW3UNEMB"
   },
   "outputs": [],
   "source": [
    "with open(\"real_valid.txt\", \"rb\") as fp:\n",
    "    real_valid = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "qSCH0eSDNHhB"
   },
   "outputs": [],
   "source": [
    "#import os\n",
    "#os.mkdir('real_pics')\n",
    "#os.mkdir('real_pics/train')\n",
    "#os.mkdir('real_pics/test')\n",
    "#os.mkdir('real_pics/valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "SWPmmp6-NNIE"
   },
   "outputs": [],
   "source": [
    "#7min\n",
    "#create an image for each element in real_train/real_test/real_valid lists and saving it in\n",
    "#real_pics/train/, real_pics/test/, real_pics/valid/\n",
    "for real in real_train:\n",
    "    create_image(real, 'real_pics/train/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "ssjYdrWbNSto"
   },
   "outputs": [],
   "source": [
    "#4min\n",
    "for real in real_test:\n",
    "    create_image(real, 'real_pics/test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "RhR5M50IQr3g"
   },
   "outputs": [],
   "source": [
    "#4min\n",
    "for real in real_valid:\n",
    "    create_image(real, 'real_pics/valid/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "kt6onkW6R1Sz"
   },
   "outputs": [],
   "source": [
    "#data division, manipulating homoglyph domains (score of 1.0)\n",
    "train = [fake[1] for fake in data['train'] if fake[2] == 1.0]\n",
    "test = [fake[1] for fake in data['test'] if fake[2] == 1.0]\n",
    "valid = [fake[1] for fake in data['validate'] if fake[2] == 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5phhFFoKTAfe",
    "outputId": "7b3a0f0d-8a40-4b03-8bdb-9bccdb30a368"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "677675 178410 35669\n"
     ]
    }
   ],
   "source": [
    "print(len(list(set(train))), len(list(set(test))), len(list(set(valid))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "dDWQ_WbnS3j4"
   },
   "outputs": [],
   "source": [
    "#eliminating duplicates\n",
    "uniq_train = list(set(train))[:83803]\n",
    "uniq_test = list(set(test))[:49711]\n",
    "uniq_valid = list(set(valid))[:44141]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2XnBKw8yS8-E",
    "outputId": "e5247952-0c0f-482e-ecc1-1b0d051e08a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83803 49711 35669\n"
     ]
    }
   ],
   "source": [
    "print(len(uniq_train), len(uniq_test), len(uniq_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "KUnQf8ZiTEHv"
   },
   "outputs": [],
   "source": [
    "#saving data in files\n",
    "with open(\"fake_train.txt\", \"wb\") as fp:\n",
    "    pickle.dump(uniq_train, fp)\n",
    "\n",
    "with open(\"fake_test.txt\", \"wb\") as fp:\n",
    "    pickle.dump(uniq_test, fp)\n",
    "\n",
    "with open(\"fake_valid.txt\", \"wb\") as fp:\n",
    "    pickle.dump(uniq_valid, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "NgOKX1BUTGRn"
   },
   "outputs": [],
   "source": [
    "with open(\"fake_train.txt\", \"rb\") as fp:\n",
    "    fake_train = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "YWGWc9dXTJCO"
   },
   "outputs": [],
   "source": [
    "with open(\"fake_test.txt\", \"rb\") as fp:\n",
    "    fake_test = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "E2W7LvunTKx5"
   },
   "outputs": [],
   "source": [
    "with open(\"fake_valid.txt\", \"rb\") as fp:\n",
    "    fake_valid = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "D2JVyWyGTMPO"
   },
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[Errno 17] File exists: 'fake_pics'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfake_pics\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m os\u001b[38;5;241m.\u001b[39mmkdir(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfake_pics/train\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m os\u001b[38;5;241m.\u001b[39mmkdir(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfake_pics/test\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: 'fake_pics'"
     ]
    }
   ],
   "source": [
    "os.mkdir('fake_pics')\n",
    "os.mkdir('fake_pics/train')\n",
    "os.mkdir('fake_pics/test')\n",
    "os.mkdir('fake_pics/valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "3Wa8KTMsTN47"
   },
   "outputs": [],
   "source": [
    "#create an image for each element in fake_train/fake_test/fake_valid lists and saving it in\n",
    "#fake_pics/train/, fake_pics/test/, fake_pics/valid/\n",
    "#8min\n",
    "for fake in fake_train:\n",
    "    create_image(fake,'fake_pics/train/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "FKAVJlLITRPJ"
   },
   "outputs": [],
   "source": [
    "#5min\n",
    "for fake in fake_test:\n",
    "    create_image(fake,'fake_pics/test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "oQyH3mjtVM_I"
   },
   "outputs": [],
   "source": [
    "#3min\n",
    "for fake in fake_valid:\n",
    "    create_image(fake,'fake_pics/valid/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mYe5-CnLWWS3"
   },
   "outputs": [],
   "source": [
    "os.mkdir('final_train')\n",
    "os.mkdir('final_train/real')\n",
    "os.mkdir('final_train/fake')\n",
    "\n",
    "os.mkdir('final_valid')\n",
    "os.mkdir('final_valid/real')\n",
    "os.mkdir('final_valid/fake')\n",
    "\n",
    "os.mkdir('final_test')\n",
    "os.mkdir('final_test/real')\n",
    "os.mkdir('final_test/fake')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "1EvEsth6XMN1"
   },
   "outputs": [],
   "source": [
    "#copying all the images from the directory real_pics/train/ to the directory final_train/real/\n",
    "import os\n",
    "from os import path\n",
    "import shutil\n",
    "\n",
    "src = \"real_pics/train/\"\n",
    "dst = \"final_train/real/\"\n",
    "\n",
    "cnt = 0\n",
    "#files = [i for i in os.listdir(src) if i.startswith(\"CTASK\") and path.isfile(path.join(src, i))]\n",
    "files = [i for i in os.listdir(src)]\n",
    "for f in files:\n",
    "        shutil.copy(path.join(src, f), dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "FEV5NXvpXOpD"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os import path\n",
    "import shutil\n",
    "\n",
    "src = \"real_pics/test/\"\n",
    "dst = \"final_train/real/\"\n",
    "\n",
    "cnt = 0\n",
    "#files = [i for i in os.listdir(src) if i.startswith(\"CTASK\") and path.isfile(path.join(src, i))]\n",
    "files = [i for i in os.listdir(src)]\n",
    "for f in files:\n",
    "        shutil.copy(path.join(src, f), dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "NTnUB9hnXT2B"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os import path\n",
    "import shutil\n",
    "\n",
    "src = \"fake_pics/train/\"\n",
    "dst = \"final_train/fake/\"\n",
    "\n",
    "cnt = 0\n",
    "#files = [i for i in os.listdir(src) if i.startswith(\"CTASK\") and path.isfile(path.join(src, i))]\n",
    "files = [i for i in os.listdir(src)]\n",
    "for f in files:\n",
    "        shutil.copy(path.join(src, f), dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "eBhYCj61XW7c"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os import path\n",
    "import shutil\n",
    "\n",
    "src = \"fake_pics/test/\"\n",
    "dst = \"final_train/fake/\"\n",
    "\n",
    "cnt = 0\n",
    "#files = [i for i in os.listdir(src) if i.startswith(\"CTASK\") and path.isfile(path.join(src, i))]\n",
    "files = [i for i in os.listdir(src)]\n",
    "for f in files:\n",
    "        shutil.copy(path.join(src, f), dst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "F_k-1yXgXZdr"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os import path\n",
    "import shutil\n",
    "\n",
    "src = \"real_pics/valid/\"\n",
    "dst = \"final_valid/real/\"\n",
    "\n",
    "cnt = 0\n",
    "#files = [i for i in os.listdir(src) if i.startswith(\"CTASK\") and path.isfile(path.join(src, i))]\n",
    "files = [i for i in os.listdir(src)]\n",
    "for f in files:\n",
    "        shutil.copy(path.join(src, f), dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "C-GeCKJ5Xbqw"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os import path\n",
    "import shutil\n",
    "\n",
    "src = \"fake_pics/valid/\"\n",
    "dst = \"final_valid/fake/\"\n",
    "\n",
    "cnt = 0\n",
    "#files = [i for i in os.listdir(src) if i.startswith(\"CTASK\") and path.isfile(path.join(src, i))]\n",
    "files = [i for i in os.listdir(src)]\n",
    "for f in files:\n",
    "        shutil.copy(path.join(src, f), dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "PZ1PtLFBXdr4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-22 10:12:21.588378: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "4KZuNMSPXfpR"
   },
   "outputs": [],
   "source": [
    "from keras import layers, models, optimizers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 3)))\n",
    "model.add(layers.MaxPool2D(2, 2))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPool2D(2, 2))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPool2D(2, 2))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPool2D(2, 2))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dropout(0.5)) # Note the only change is that we added dropout here\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.Adam(learning_rate=1e-4), #lr\n",
    "              metrics=['acc', tf.keras.metrics.AUC()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tAiUo859Xhwz",
    "outputId": "c9f3ef3c-0fb9-4de3-f008-778fd6524ee5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 336262 images belonging to 2 classes.\n",
      "Found 80117 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Rescale pixel values from [0, 255] to [0, 1]\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# The list of classes will be automatically inferred from the subdirectory names/structure under train_dir\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'final_train',\n",
    "    target_size=(256, 256), # resize all images to 224 x 224\n",
    "    batch_size=50,\n",
    "    class_mode='binary') # because we use binary_crossentropy loss we need binary labels\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    'final_valid',\n",
    "    target_size=(256, 256),\n",
    "    batch_size=50,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 490
    },
    "id": "Nz7fnUpbXyXh",
    "outputId": "ff8f17b8-8ec3-45e8-bf88-0038564419d2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tg/qlmdrnrj54bbs6n3xgd83bmm0000gn/T/ipykernel_1129/1827444606.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 61/500 [==>...........................] - ETA: 17:39 - loss: 0.4493 - acc: 0.8131 - auc: 0.7858"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=500,\n",
    "    epochs=30,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O2AkR7JPAfPV"
   },
   "outputs": [],
   "source": [
    "os.mkdir('trocr_real_pics')\n",
    "os.mkdir('trocr_fake_pics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3ROyXYBD0wxF"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('/content/defRes.json', 'r') as file:\n",
    "    data = json.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t8i2W8d21Fn8"
   },
   "outputs": [],
   "source": [
    "for stringa in data:\n",
    "\n",
    "    create_image(stringa, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9XePjxlS1Q4G"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing import image as keras_image  # Rinomina 'image' in 'keras_image'\n",
    "import numpy as np\n",
    "\n",
    "#model = tf.keras.models.load_model('nome_del_tuo_modello.h5')\n",
    "\n",
    "# Carica il file JSON con le stringhe\n",
    "import json\n",
    "\n",
    "with open('/content/defRes.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Inizializza contatori\n",
    "real_count = 0\n",
    "fake_count = 0\n",
    "real_strings = []\n",
    "\n",
    "# Definisci la cartella di output\n",
    "output_path = '/content/trocr_fake_pics/'\n",
    "\n",
    "# Itera attraverso le stringhe nel JSON\n",
    "for stringa in data:\n",
    "    img_path = output_path + stringa + '.png'\n",
    "    img = keras_image.load_img(img_path, target_size=(256, 256))  # Usa 'keras_image' invece di 'image'\n",
    "    img = keras_image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = img / 255.0\n",
    "\n",
    "    # Effettua la previsione\n",
    "    predictions = model.predict(img)\n",
    "\n",
    "    # Le previsioni saranno un vettore con un valore tra 0 e 1, dove 0 potrebbe rappresentare \"reale\" e 1 \"falso\"\n",
    "    threshold = 0.5  # Ad esempio, usa 0.5 come soglia\n",
    "    if predictions[0] >= threshold:\n",
    "        print(\"real\")\n",
    "        real_count += 1\n",
    "        real_strings.append(stringa)\n",
    "    else:\n",
    "        fake_count += 1\n",
    "        print(\"fake\")\n",
    "\n",
    "print(f\"Numero di reali: {real_count}\")\n",
    "print(f\"Numero di falsi: {fake_count}\")\n",
    "print(\"Stringhe reali:\")\n",
    "print(real_strings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dkCgwpc_1RRL"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Dati\n",
    "total = 700\n",
    "real_count = 141  # Sostituisci con il tuo conteggio reale\n",
    "fake_count = 559  # Sostituisci con il tuo conteggio falso\n",
    "labels = ['Reali', 'Falsi']\n",
    "sizes = [real_count, fake_count]\n",
    "colors = ['#4CAF50', '#FF5733']\n",
    "\n",
    "# Calcola le percentuali\n",
    "percentages = [count / total * 100 for count in sizes]\n",
    "\n",
    "# Crea il grafico a torta\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=140,\n",
    "        shadow=True, wedgeprops={'edgecolor': 'gray'})\n",
    "plt.axis('equal')\n",
    "plt.title('Distribuzione tra Reali e Falsi (Rispetto al Totale 700)', fontsize=16)\n",
    "\n",
    "# Aggiungi una legenda\n",
    "plt.legend(labels, title=\"Categorie\", loc=\"best\")\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
